{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft50efEze9Fk"
      },
      "outputs": [],
      "source": [
        "#1 What is NumPy, and why is it widely used in Python?\n",
        "\n",
        "* NumPy (short for Numerical Python) is an open-source Python library widely used for numerical computing. It provides support for creating and manipulating large,\n",
        " multi-dimensional arrays and matrices, along with a collection of mathematical functions to perform operations on these data structures efficiently.\n",
        "\n",
        "Key Features of NumPy:\n",
        " 1. Multi-dimensional Array Object (ndarray):\n",
        " • At the core of NumPy is the ndarray, a fast, flexible container for homogeneous data. It supports arrays of arbitrary dimensions.\n",
        " 2. Vectorized Operations:\n",
        " • NumPy allows you to perform mathematical and logical operations on arrays without the need for explicit loops, which makes it faster and more concise.\n",
        " 3. Mathematical Functions:\n",
        " • It includes functions for linear algebra, Fourier analysis, statistical operations, and more.\n",
        " 4. Efficiency:\n",
        " • NumPy is implemented in C, enabling operations on large datasets to be much faster than using Python’s built-in lists.\n",
        " 5. Interoperability:\n",
        " • It can work seamlessly with other libraries such as Pandas, Matplotlib, and SciPy, making it a cornerstone of the Python scientific computing ecosystem.\n",
        " 6. Broadcasting:\n",
        " • This feature simplifies working with arrays of different shapes, enabling element-wise operations without additional coding.\n",
        " 7. Data Handling:\n",
        " • It provides tools for reading and writing arrays to disk and interacting with other formats.\n",
        "\n",
        "Why is NumPy Widely Used?\n",
        " 1. Performance:\n",
        " • Operations with NumPy arrays are significantly faster than operations with Python lists due to its optimized implementation in C and its use of vectorized operations.\n",
        " 2. Ease of Use:\n",
        " • NumPy provides an intuitive syntax and powerful features that simplify complex numerical computations.\n",
        " 3. Foundation for Other Libraries:\n",
        " • Many Python libraries, like Pandas, SciPy, and TensorFlow, are built on top of NumPy, making it an essential tool for data science, machine learning, and scientific computing.\n",
        " 4. Large Community and Documentation:\n",
        " • A vast community of developers and extensive documentation make it easy to learn and troubleshoot issues.\n",
        " 5. Cross-Disciplinary Applications:\n",
        " • It is used in various domains like machine learning, finance, engineering, and physics for tasks ranging from simple arithmetic to complex simulations.\n",
        "\n",
        "#2 How does broadcasting work in NumPy?\n",
        "\n",
        "* Broadcasting in NumPy is a powerful mechanism that allows arrays with different shapes to be used together in arithmetic operations. Instead of requiring arrays to\n",
        " have the exact same shape, NumPy automatically expands the smaller array’s dimensions to match the larger array’s shape, without copying data.\n",
        "\n",
        "Rules for Broadcasting\n",
        "\n",
        "Broadcasting follows these rules to align array shapes:\n",
        " 1. Right Alignment: The shapes of the arrays are aligned starting from the trailing dimensions (i.e., the last dimensions).\n",
        " 2. Dimension Compatibility:\n",
        " • Dimensions are considered compatible if:\n",
        " • They are equal.\n",
        " • One of them is 1.\n",
        " • If a dimension is 1, it is “stretched” to match the corresponding dimension of the other array.\n",
        "\n",
        "If the arrays’ shapes cannot be made compatible using these rules, a broadcasting error is raised.\n",
        "\n",
        "Examples of Broadcasting\n",
        " 1. Scalar and Array:\n",
        "When performing operations between a scalar and an array, the scalar is broadcast to match the array’s shape.\n",
        "\n",
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = 2\n",
        "result = a * b  # Scalar `b` is broadcast to [2, 2, 2]\n",
        "print(result)  # Output: [2, 4, 6]\n",
        "\n",
        "\n",
        " 2. Arrays with Different Shapes:\n",
        "\n",
        "a = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
        "b = np.array([10, 20, 30])            # Shape: (3,)\n",
        "result = a + b\n",
        "print(result)\n",
        "# Output:\n",
        "# [[11, 22, 33],\n",
        "#  [14, 25, 36]]\n",
        "\n",
        "Here, b is broadcast to shape (2, 3).\n",
        "\n",
        " 3. Adding a Column Vector to a Matrix:\n",
        "\n",
        "a = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
        "b = np.array([[10], [20]])            # Shape: (2, 1)\n",
        "result = a + b\n",
        "print(result)\n",
        "# Output:\n",
        "# [[11, 12, 13],\n",
        "#  [24, 25, 26]]\n",
        "\n",
        "Here, b is broadcast to shape (2, 3).\n",
        "\n",
        "benefits of broadcasting\n",
        " • Efficiency: Avoids explicit replication of data, saving memory and computation time.\n",
        " • Ease of Use: Simplifies code by eliminating the need for explicit loops or shape manipulation.\n",
        "By understanding broadcasting, you can write more efficient and concise NumPy code for operations on arrays of different shapes.\n",
        "\n",
        "#3 What is a Pandas DataFrame)\n",
        "* A Pandas DataFrame is a two-dimensional, mutable, and labeled data structure provided by the Pandas library in Python. It is designed to efficiently\n",
        " store and manipulate tabular data, making it one of the most widely used tools for data analysis and manipulation.\n",
        "\n",
        "Characteristics of a DataFrame\n",
        " 1. Tabular Structure:\n",
        " • A DataFrame is similar to a table in a relational database or an Excel spreadsheet, with rows and columns.\n",
        " 2. Labeled Axes:\n",
        " • Each row has an index (row label), and each column has a name (column label), which makes it easy to access and manipulate specific data.\n",
        " 3. Heterogeneous Data:\n",
        " • Each column can contain a different type of data (e.g., integers, floats, strings, etc.).\n",
        " 4. Two-Dimensional:\n",
        " • DataFrames organize data in two dimensions: rows and columns.\n",
        " 5. Integration:\n",
        " • Built on top of NumPy, it is optimized for numerical operations and compatible with other Python libraries like Matplotlib and Scikit-learn.\n",
        "\n",
        "Creating a Pandas DataFrame\n",
        " 1. From a Dictionary:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"Age\": [25, 30, 35],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "    Name  Age         City\n",
        "0   Alice   25     New York\n",
        "1     Bob   30  Los Angeles\n",
        "2  Charlie   35      Chicago\n",
        "\n",
        "\n",
        " 2. From a NumPy Array:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "array = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "df = pd.DataFrame(array, columns=[\"A\", \"B\"])\n",
        "print(df)\n",
        "\n",
        "\n",
        " 3. From CSV or Excel Files:\n",
        "\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df = pd.read_excel(\"data.xlsx\")\n",
        "\n",
        "Common Operations\n",
        " 1. Accessing Data:\n",
        " • Access a column:\n",
        "\n",
        "print(df[\"Name\"])\n",
        "\n",
        "\n",
        " • Access a row:\n",
        "\n",
        "print(df.loc[0])   # By index\n",
        "print(df.iloc[0])  # By position\n",
        "\n",
        "\n",
        " 2. Filtering Data:\n",
        "\n",
        "filtered_df = df[df[\"Age\"] > 30]\n",
        "print(filtered_df)\n",
        "\n",
        "\n",
        " 3. Adding/Removing Columns:\n",
        "\n",
        "df[\"Country\"] = [\"USA\", \"USA\", \"USA\"]  # Add a column\n",
        "df.drop(\"Country\", axis=1, inplace=True)  # Remove a column\n",
        "\n",
        "\n",
        " 4. Statistical Analysis:\n",
        "\n",
        "print(df.describe())  # Get summary statistics\n",
        "print(df[\"Age\"].mean())  # Compute the mean of a column\n",
        "\n",
        "Advantages of Pandas DataFrame\n",
        " 1. Efficient and Flexible:\n",
        " • Handles large datasets efficiently and provides a rich set of operations for data manipulation.\n",
        " 2. Easy Integration:\n",
        " • Reads and writes to multiple formats like CSV, Excel, SQL, JSON, and more.\n",
        " 3. Built-In Functionality:\n",
        " • Supports data filtering, aggregation, reshaping, and merging operations.\n",
        " 4. Community and Ecosystem:\n",
        " • A large user base and extensive documentation make it easy to learn and use.\n",
        "\n",
        "#4 Explain the use of the groupby() method in Pandas?\n",
        "* The groupby() method in Pandas is used to group data based on one or more columns and perform aggregate operations (e.g., sum, mean, count) on these groups. It is a\n",
        " powerful tool for data analysis, enabling you to summarize, analyze, and transform data based on categorical values.\n",
        "\n",
        "How groupby() Works\n",
        "\n",
        "The groupby() operation involves three steps:\n",
        " 1. Splitting: Divides the data into groups based on a specified column or index.\n",
        " 2. Applying: Performs a function (e.g., aggregation, transformation, or filtration) on each group.\n",
        " 3. Combining: Combines the results into a new DataFrame or Series.\n",
        "\n",
        "Syntax\n",
        "\n",
        "DataFrame.groupby(by, axis=0, level=None, as_index=True, sort=True)\n",
        "\n",
        " • by: Specifies the column(s) or key(s) to group by.\n",
        " • axis: Determines whether to group by rows (default, axis=0) or columns (axis=1).\n",
        " • as_index: If True, the grouped column becomes the index of the result. If False, it remains as a normal column.\n",
        "\n",
        "Examples of groupby()\n",
        " 1. Basic Aggregation:\n",
        "Group data by a single column and calculate an aggregate function like mean or sum:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Category\": [\"A\", \"B\", \"A\", \"B\", \"A\", \"C\"],\n",
        "    \"Values\": [10, 20, 30, 40, 50, 60]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Group by 'Category' and compute the sum\n",
        "grouped = df.groupby(\"Category\")[\"Values\"].sum()\n",
        "print(grouped)\n",
        "\n",
        "Output:\n",
        "\n",
        "Category\n",
        "A     90\n",
        "B     60\n",
        "C     60\n",
        "Name: Values, dtype: int64\n",
        "\n",
        "\n",
        " 2. Multiple Aggregations:\n",
        "Use different aggregation functions for different columns:\n",
        "\n",
        "data = {\n",
        "    \"Category\": [\"A\", \"A\", \"B\", \"B\", \"C\"],\n",
        "    \"Values1\": [10, 20, 30, 40, 50],\n",
        "    \"Values2\": [5, 15, 25, 35, 45]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "grouped = df.groupby(\"Category\").agg({\"Values1\": \"sum\", \"Values2\": \"mean\"})\n",
        "print(grouped)\n",
        "\n",
        "Output:\n",
        "\n",
        "          Values1  Values2\n",
        "Category\n",
        "A              30     10.0\n",
        "B              70     30.0\n",
        "C              50     45.0\n",
        "\n",
        "\n",
        " 3. Using Multiple Columns in groupby():\n",
        "Group by more than one column:\n",
        "\n",
        "data = {\n",
        "    \"Category\": [\"A\", \"A\", \"B\", \"B\", \"C\"],\n",
        "    \"Type\": [\"X\", \"Y\", \"X\", \"Y\", \"X\"],\n",
        "    \"Values\": [10, 20, 30, 40, 50]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "grouped = df.groupby([\"Category\", \"Type\"])[\"Values\"].sum()\n",
        "print(grouped)\n",
        "\n",
        "Output:\n",
        "\n",
        "Category  Type\n",
        "A         X       10\n",
        "          Y       20\n",
        "B         X       30\n",
        "          Y       40\n",
        "C         X       50\n",
        "Name: Values, dtype: int64\n",
        "\n",
        "\n",
        " 4. Transformation:\n",
        "Use groupby() with a transformation function to create a column that reflects group-level calculations:\n",
        "\n",
        "df[\"GroupMean\"] = df.groupby(\"Category\")[\"Values\"].transform(\"mean\")\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "  Category Type  Values  GroupMean\n",
        "0        A    X      10       15.0\n",
        "1        A    Y      20       15.0\n",
        "2        B    X      30       35.0\n",
        "3        B    Y      40       35.0\n",
        "4        C    X      50       50.0\n",
        "\n",
        "\n",
        " 5. Filtering Groups:\n",
        "Retain only groups that meet a specific condition:\n",
        "\n",
        "filtered = df.groupby(\"Category\").filter(lambda x: x[\"Values\"].mean() > 20)\n",
        "print(filtered)\n",
        "\n",
        "Output:\n",
        "\n",
        "  Category Type  Values\n",
        "2        B    X      30\n",
        "3        B    Y      40\n",
        "4        C    X      50\n",
        "\n",
        "By leveraging groupby(), you can perform complex data analysis tasks in Pandas efficiently and effectively.\n",
        "\n",
        "#5 Why is Seaborn preferred for statistical visualizations?\n",
        "*Seaborn is a Python library built on top of Matplotlib that is widely preferred for creating statistical visualizations. It is specifically designed to make\n",
        " complex visualizations easy to produce and aesthetically pleasing. Here are the key reasons why Seaborn is preferred:\n",
        "\n",
        "1. Built-In Statistical Functions\n",
        " • Seaborn integrates statistical estimation and plotting directly into its functions, simplifying tasks like regression analysis, confidence intervals, and\n",
        "  kernel density estimation.\n",
        " • Examples:\n",
        " • sns.regplot() for regression plots.\n",
        " • sns.kdeplot() for visualizing distributions with kernel density estimation.\n",
        "\n",
        "2. Beautiful Default Styles\n",
        " • Seaborn has attractive and informative default color palettes and plot styles, eliminating the need for extensive customization.\n",
        " • Example: The sns.set_theme() function allows you to set consistent themes like “darkgrid” or “whitegrid.”\n",
        "\n",
        "3. High-Level Abstractions\n",
        " • Seaborn simplifies the process of creating complex plots, such as faceted grids or multi-variable visualizations, with fewer lines of code.\n",
        " • Examples:\n",
        " • sns.catplot() for categorical plots.\n",
        " • sns.relplot() for scatter or line plots with support for multiple dimensions.\n",
        "\n",
        "4. Easy Handling of Pandas DataFrames\n",
        " • Seaborn is designed to work seamlessly with Pandas DataFrames, allowing you to specify data columns directly by their names without extra preprocessing.\n",
        " • Example:\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = pd.DataFrame({\n",
        "    \"Category\": [\"A\", \"B\", \"A\", \"B\"],\n",
        "    \"Value\": [10, 20, 15, 25]\n",
        "})\n",
        "\n",
        "sns.barplot(x=\"Category\", y=\"Value\", data=data)\n",
        "\n",
        "5. Advanced Categorical Plots\n",
        " • Seaborn provides specialized functions for visualizing categorical data, such as:\n",
        " • sns.boxplot() for box plots.\n",
        " • sns.violinplot() for combined box and kernel density plots.\n",
        " • sns.stripplot() and sns.swarmplot() for jittered scatter plots.\n",
        "\n",
        "6. Multi-Variable Relationships\n",
        " • Seaborn excels at visualizing relationships between multiple variables with functions like:\n",
        " • sns.pairplot(): Creates scatter plots for all pairwise combinations of numerical variables in a dataset.\n",
        " • sns.heatmap(): Visualizes data as a color-encoded matrix, useful for correlation matrices.\n",
        "\n",
        "7. Faceted Plots\n",
        " • Seaborn’s FacetGrid allows you to create plots with subsets of data split across multiple facets (subplots) based on a categorical variable.\n",
        " • Example:\n",
        "\n",
        "sns.catplot(x=\"day\", y=\"total_bill\", hue=\"sex\", col=\"time\", data=tips, kind=\"bar\")\n",
        "\n",
        "8. Seamless Integration with Matplotlib\n",
        " • While Seaborn simplifies plotting, it is fully compatible with Matplotlib, allowing for advanced customization if needed.\n",
        "\n",
        "9. Rich Color Palettes\n",
        " • Seaborn offers built-in color palettes like coolwarm, viridis, and categorical palettes (pastel, deep, etc.) for visual distinction.\n",
        " • Example:\n",
        "\n",
        "sns.set_palette(\"pastel\")\n",
        "\n",
        "10. Handling Missing Data\n",
        " • Seaborn handles missing values gracefully, often dropping them automatically or providing options to visualize them without errors.\n",
        "\n",
        "Applications\n",
        " • Data exploration (e.g., examining distributions or relationships).\n",
        " • Statistical analysis (e.g., visualizing trends and confidence intervals).\n",
        " • Preprocessing and feature analysis for machine learning.\n",
        " • Creating publication-quality plots.\n",
        "\n",
        "#6 What are the differences between NumPy arrays and Python lists?\n",
        "* Differences Between NumPy Arrays, Python Lists, and Arrays (from the array module)\n",
        "\n",
        "Feature NumPy Arrays Python Lists array Module Arrays\n",
        "Definition A powerful multidimensional array object from NumPy. A general-purpose, built-in collection type in Python. A space-efficient array for homogeneous data types.\n",
        "Data Type Requires a single data type for all elements. Can hold elements of mixed data types. Requires a single data type for all elements.\n",
        "Performance Highly optimized for numerical operations. Slower due to Python’s dynamic typing. Faster than lists but less optimized than NumPy.\n",
        "Memory Efficiency More memory-efficient for large datasets. Less efficient; stores metadata for each element. Efficient for homogeneous data, less flexible.\n",
        "Functionality Rich library for mathematical, statistical, and linear algebra operations. Limited functionality; relies on loops or other libraries for numerical tasks.\n",
        " Limited to basic operations; lacks advanced features.\n",
        "Dimensionality Supports multidimensional arrays (e.g., 2D, 3D). Primarily one-dimensional; nested lists can mimic multidimensionality. Typically one-dimensional.\n",
        "Type Checking Strongly enforces data types (e.g., float64, int32). Allows mixed data types (e.g., strings, integers). Enforces a single data type, specified on creation.\n",
        "Element-wise Operations Supports element-wise operations directly (e.g., array1 + array2). Requires loops or comprehensions for such operations. Limited or no support for\n",
        "element-wise operations.\n",
        "Ease of Use Designed specifically for numerical and scientific tasks. General-purpose; easy for beginners. Suitable for simple, low-level use cases.\n",
        "\n",
        "1. NumPy Arrays\n",
        "\n",
        "Strengths:\n",
        " • Best choice for scientific computing and large datasets.\n",
        " • Supports advanced mathematical operations (e.g., matrix multiplication, Fourier transforms).\n",
        " • Enables broadcasting for operations on arrays of different shapes.\n",
        "\n",
        "Weaknesses:\n",
        " • Requires the installation of the NumPy library.\n",
        " • Strictly homogeneous data (all elements must be of the same type).\n",
        "\n",
        "Example:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "print(arr + 2)  # Element-wise operation\n",
        "\n",
        "2. Python Lists\n",
        "\n",
        "Strengths:\n",
        " • Built into Python; no additional libraries required.\n",
        " • Flexible: supports elements of mixed data types.\n",
        " • Easy to learn and use for general programming tasks.\n",
        "\n",
        "Weaknesses:\n",
        " • Slower for numerical operations due to dynamic typing.\n",
        " • Consumes more memory because of type and object metadata.\n",
        " • Requires loops or comprehensions for element-wise operations.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Create a Python list\n",
        "lst = [1, 2, 3, 4]\n",
        "print([x + 2 for x in lst])  # Requires a loop for element-wise operation\n",
        "\n",
        "3. Arrays (from the array module)\n",
        "\n",
        "Strengths:\n",
        " • Built into Python; no additional installation required.\n",
        " • More memory-efficient than lists for large datasets of homogeneous types.\n",
        " • Simple to use for small, one-dimensional arrays.\n",
        "\n",
        "Weaknesses:\n",
        " • Limited functionality compared to NumPy.\n",
        " • Only supports homogeneous data.\n",
        " • No support for multidimensional arrays or advanced operations.\n",
        "\n",
        "Example:\n",
        "\n",
        "from array import array\n",
        "\n",
        "# Create an array\n",
        "arr = array('i', [1, 2, 3, 4])  # 'i' stands for integers\n",
        "arr.append(5)\n",
        "print(arr)\n",
        "\n",
        "When to Use Each\n",
        " • NumPy Arrays: Ideal for numerical and scientific computing, handling large datasets, or working with matrices.\n",
        " • Python Lists: Best for general-purpose programming when flexibility and mixed data types are needed.\n",
        " • array Module Arrays: Suitable for simple, memory-efficient one-dimensional arrays, but typically replaced by NumPy arrays for more complex tasks.\n",
        "\n",
        "By understanding their differences, you can choose the right structure for your specific use case.\n",
        "\n",
        "#7 What is a heatmap, and when should it be used?\n",
        "* A heatmap is a graphical representation of data in a matrix format, where individual values in the matrix are represented as colors. The intensity or shade of the\n",
        "color corresponds to the magnitude of the value in the data, making it easy to visualize patterns, correlations, or densities.\n",
        "\n",
        "Features of a Heatmap\n",
        " 1. Data Representation: Represents numerical data in a tabular format using colors.\n",
        " 2. Axes:\n",
        " • Rows and columns represent the two dimensions of the data.\n",
        " • Labels on the axes help identify the variables or categories.\n",
        " 3. Color Gradients: A color scale (e.g., from light to dark or cool to warm colors) is used to depict the range of values.\n",
        " 4. Customization: Additional annotations, like numeric values, can be added to enhance interpretability.\n",
        "\n",
        "When to Use a Heatmap\n",
        "\n",
        "Heatmaps are particularly useful in the following scenarios:\n",
        " 1. Finding Patterns in Data:\n",
        " • Useful for identifying clusters, trends, or anomalies in datasets.\n",
        " • Example: Customer behavior analysis in e-commerce.\n",
        " 2. Correlation Analysis:\n",
        " • Visualize relationships between variables using a correlation matrix.\n",
        " • Example: Displaying the correlation between financial indicators in a dataset.\n",
        " 3. Matrix-Like Data:\n",
        " • Suitable for displaying datasets that are inherently matrix-like, such as confusion matrices or distance matrices.\n",
        " • Example: Showing the confusion matrix in machine learning.\n",
        " 4. Hierarchical Clustering:\n",
        " • Combine heatmaps with dendrograms to represent clusters.\n",
        " • Example: Gene expression data in bioinformatics.\n",
        " 5. Density Visualization:\n",
        " • Represent the density of occurrences over a two-dimensional grid.\n",
        " • Example: Heatmaps of traffic density in cities.\n",
        " 6. Geospatial Data:\n",
        " • Visualizing intensity or density across geographical regions (e.g., population density).\n",
        " • Example: Weather temperature distribution on a map.\n",
        "\n",
        "Example Use Cases\n",
        " 1. Correlation Matrix:\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {\n",
        "    \"A\": [1, 2, 3, 4],\n",
        "    \"B\": [4, 3, 2, 1],\n",
        "    \"C\": [2, 4, 1, 3]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr = df.corr()\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        " 2. Visualizing a Confusion Matrix:\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_true = [1, 0, 1, 1, 0, 1]\n",
        "y_pred = [1, 0, 1, 0, 0, 1]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot heatmap\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        " 3. Gene Expression Analysis (Bioinformatics):\n",
        "\n",
        "sns.heatmap(data=gene_expression_data, cmap=\"viridis\")\n",
        "plt.show()\n",
        "\n",
        "Advantages of Heatmaps\n",
        " 1. Easy Pattern Recognition:\n",
        " • Colors make it intuitive to identify patterns, clusters, and outliers.\n",
        " 2. Compact Visualization:\n",
        " • Displays a large amount of data in a single, compact figure.\n",
        " 3. Customizable:\n",
        " • You can annotate, change color palettes, and add axis labels.\n",
        "\n",
        "#8 What does the term “vectorized operation” mean in NumPy?\n",
        "\n",
        "* A vectorized operation in NumPy refers to performing operations on entire arrays (vectors, matrices, or higher-dimensional arrays) element-wise without the need for explicit loops.\n",
        " These operations are implemented internally using optimized, low-level C and Fortran routines, making them significantly faster and more efficient than\n",
        "  manually iterating over elements in Python.\n",
        "\n",
        "Examples of Vectorized Operations\n",
        " 1. Basic Arithmetic\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "\n",
        "# Element-wise addition\n",
        "c = a + b  # [5, 7, 9]\n",
        "\n",
        "# Element-wise multiplication\n",
        "d = a * b  # [4, 10, 18]\n",
        "\n",
        "\n",
        " 2. Mathematical Functions\n",
        "NumPy provides vectorized implementations of mathematical functions like sin, cos, and exp:\n",
        "\n",
        "a = np.array([0, np.pi / 2, np.pi])\n",
        "\n",
        "# Element-wise sine\n",
        "np.sin(a)  # [0, 1, 0]\n",
        "\n",
        "\n",
        " 3. Comparison Operations\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([2, 2, 2])\n",
        "\n",
        "# Element-wise comparison\n",
        "a > b  # [False, False, True]\n",
        "\n",
        "\n",
        " 4. Broadcasting in Vectorized Operations\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "\n",
        "# Adding a scalar to each element\n",
        "b = a + 10  # [11, 12, 13]\n",
        "\n",
        "\n",
        " 5. Matrix Operations\n",
        "\n",
        "a = np.array([[1, 2], [3, 4]])\n",
        "b = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Element-wise multiplication\n",
        "c = a * b  # [[5, 12], [21, 32]]\n",
        "\n",
        "# Matrix multiplication\n",
        "d = a @ b  # [[19, 22], [43, 50]]\n",
        "\n",
        "Advantages of Vectorized Operations\n",
        " 1. Speed: Significantly faster than Python loops due to underlying C optimizations.\n",
        " 2. Simplicity: Cleaner and more readable code without explicit iteration.\n",
        " 3. Consistency: Reduces the likelihood of bugs by eliminating manual looping logic.\n",
        " 4. Scalability: Ideal for handling large datasets or multidimensional arrays.\n",
        "\n",
        "Comparison: Vectorized vs Non-Vectorized Code\n",
        "\n",
        "Non-Vectorized Example (Using Loops)\n",
        "\n",
        "a = [1, 2, 3]\n",
        "b = [4, 5, 6]\n",
        "\n",
        "# Element-wise addition using loops\n",
        "c = [a[i] + b[i] for i in range(len(a))]\n",
        "\n",
        "Vectorized Example (Using NumPy)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "\n",
        "# Element-wise addition\n",
        "c = a + b\n",
        "\n",
        "#9 How does Matplotlib differ from Plotly?\n",
        "* Comparison: Matplotlib vs. Plotly\n",
        "\n",
        "Matplotlib and Plotly are two popular Python libraries for data visualization, each with distinct features and use cases. Below is a detailed comparison:\n",
        "\n",
        "1. Overview\n",
        "\n",
        "Feature Matplotlib Plotly\n",
        "Definition A static visualization library for 2D (and some 3D) plots. An interactive visualization library for 2D and 3D plots.\n",
        "Output Produces static plots by default (can be interactive with extensions). Produces highly interactive plots out of the box.\n",
        "Ease of Use Requires more customization for complex plots. Easier to create interactive and visually appealing plots.\n",
        "\n",
        "2. Key Features\n",
        "\n",
        "Matplotlib\n",
        " • Static Plots:\n",
        " • Generates publication-quality static visualizations.\n",
        " • Ideal for reports, papers, and reproducible results.\n",
        " • Customization:\n",
        " • Highly customizable with control over every aspect of a plot.\n",
        " • Performance:\n",
        " • Performs well with large datasets in static visualizations.\n",
        " • Extensions:\n",
        " • Libraries like Seaborn and Basemap enhance its capabilities.\n",
        " • Output Formats:\n",
        " • Supports formats like PNG, PDF, SVG, etc.\n",
        "\n",
        "Plotly\n",
        " • Interactive Plots:\n",
        " • Out-of-the-box interactivity (zooming, panning, tooltips).\n",
        " • Modern Aesthetics:\n",
        " • Stylish, default themes that require minimal customization.\n",
        " • 3D Visualizations:\n",
        " • Provides seamless 3D plotting functionality.\n",
        " • Web Integration:\n",
        " • Easily embeds plots in web applications or dashboards (e.g., with Dash).\n",
        " • Export Options:\n",
        " • Allows exporting to HTML, JSON, or static images.\n",
        "\n",
        "3. Ease of Use\n",
        "\n",
        "Matplotlib:\n",
        " • Steeper Learning Curve:\n",
        " • Requires more effort to produce advanced or polished plots.\n",
        " • Code Example:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [1, 2, 3, 4]\n",
        "y = [10, 20, 25, 30]\n",
        "\n",
        "plt.plot(x, y, label=\"Line\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.title(\"Static Plot\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "Plotly:\n",
        " • Beginner-Friendly for Interactivity:\n",
        " • Easier to create interactive, web-ready plots with minimal effort.\n",
        " • Code Example:\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Interactive scatter plot\n",
        "fig = px.scatter(x=[1, 2, 3, 4], y=[10, 20, 25, 30], title=\"Interactive Plot\")\n",
        "fig.show()\n",
        "\n",
        "4. Interactivity\n",
        "\n",
        "Aspect Matplotlib Plotly\n",
        "Interactivity Requires additional libraries (e.g., mplcursors, ipywidgets). Built-in; interactive by default.\n",
        "Features Limited interactivity (static by nature). Zooming, panning, tooltips, hover effects.\n",
        "\n",
        "5. Advanced Features\n",
        "\n",
        "Feature Matplotlib Plotly\n",
        "3D Visualization Limited; supported through mpl_toolkits. Strong support for 3D visualizations.\n",
        "Animations Requires additional setup (FuncAnimation). Easy to create animations directly.\n",
        "Dashboards Not natively supported. Integrates seamlessly with Dash.\n",
        "Geospatial Plots Requires extensions like Basemap or Cartopy. Native support (Mapbox, choropleths).\n",
        "\n",
        "6. Aesthetics\n",
        "\n",
        "Aspect Matplotlib Plotly\n",
        "Default Style Traditional (can be customized). Modern and visually appealing by default.\n",
        "Themes Requires manual customization. Comes with pre-built themes (e.g., plotly_dark).\n",
        "\n",
        "7. Performance\n",
        "\n",
        "Aspect Matplotlib Plotly\n",
        "Large Datasets Handles static visualizations efficiently. Can struggle with very large datasets due to interactivity.\n",
        "Export Speed Faster for static plots. Slower for exporting complex visualizations.\n",
        "\n",
        "#10 What is the significance of hierarchical indexing in Pandas?\n",
        "*Significance of Hierarchical Indexing in Pandas\n",
        "\n",
        "Hierarchical indexing, also known as multi-level indexing, is a powerful feature in pandas that allows you to work with data that has multiple dimensions or levels\n",
        " of index labels. It provides the ability to manage and analyze data with complex row or column structures efficiently.\n",
        "\n",
        "Key Features of Hierarchical Indexing\n",
        " 1. Multiple Index Levels:\n",
        " • You can assign more than one index level to rows or columns.\n",
        " • Each level can represent a different aspect or category of the data.\n",
        " 2. Data Organization:\n",
        " • Facilitates the organization of data into a tree-like structure.\n",
        " • Enables grouping and subsetting based on multiple criteria.\n",
        " 3. Enhanced Slicing:\n",
        " • Supports advanced slicing, filtering, and querying using multiple index levels.\n",
        "\n",
        "Benefits of Hierarchical Indexing\n",
        " 1. Simplifies Complex Data:\n",
        " • Makes it easier to manage and analyze data with multiple dimensions (e.g., time series data, group-level data).\n",
        " 2. Improved Readability:\n",
        " • Presents data in a structured and interpretable manner.\n",
        " 3. Flexible Data Aggregation:\n",
        " • Allows grouping by multiple levels for advanced aggregation and transformation tasks.\n",
        "\n",
        "Examples of Hierarchical Indexing\n",
        "\n",
        "Creating a MultiIndex DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a MultiIndex\n",
        "arrays = [\n",
        "    ['USA', 'USA', 'Canada', 'Canada'],\n",
        "    ['New York', 'California', 'Ontario', 'Quebec']\n",
        "]\n",
        "index = pd.MultiIndex.from_arrays(arrays, names=('Country', 'State/Province'))\n",
        "\n",
        "# Create a DataFrame with the MultiIndex\n",
        "data = pd.DataFrame({\n",
        "    'Population': [8.4, 39.5, 14.7, 8.4],\n",
        "    'GDP': [1.7, 3.9, 0.7, 0.4]\n",
        "}, index=index)\n",
        "\n",
        "print(data)\n",
        "\n",
        "Output:\n",
        "\n",
        "                      Population  GDP\n",
        "Country State/Province\n",
        "USA     New York             8.4  1.7\n",
        "        California          39.5  3.9\n",
        "Canada  Ontario             14.7  0.7\n",
        "        Quebec              8.4  0.4\n",
        "\n",
        "Accessing Data in MultiIndex\n",
        "\n",
        "# Access data for the USA\n",
        "print(data.loc['USA'])\n",
        "\n",
        "# Access data for California\n",
        "print(data.loc[('USA', 'California')])\n",
        "\n",
        "Group by MultiIndex Levels\n",
        "\n",
        "# Sum GDP by Country\n",
        "print(data.groupby(level='Country').sum())\n",
        "\n",
        "Output:\n",
        "\n",
        "         Population  GDP\n",
        "Country\n",
        "Canada         23.1  1.1\n",
        "USA            47.9  5.6\n",
        "\n",
        "Reshaping with Hierarchical Indexing\n",
        "\n",
        "# Unstacking (convert inner index to columns)\n",
        "print(data.unstack())\n",
        "\n",
        "# Stacking (convert columns back to inner index)\n",
        "print(data.stack())\n",
        "\n",
        "Limitations\n",
        " 1. Complexity:\n",
        " • MultiIndex can add complexity to data manipulation for beginners.\n",
        " 2. Performance Overhead:\n",
        " • May require additional computational resources for large datasets.\n",
        " 3. Learning Curve:\n",
        " • Requires understanding of pandas’ advanced indexing and reshaping methods.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Hierarchical indexing is significant in pandas as it enhances the ability to handle complex, multi-dimensional data. It simplifies data organization, querying,\n",
        " and analysis, making it a vital tool for data scientists and analysts working with structured datasets.\n",
        "\n",
        "#11 What is the role of Seaborn’s pairplot() function?\n",
        "* role of Seaborn's pairplot() function\n",
        "\n",
        "The pairplot() function in Seaborn is a powerful tool for exploratory data analysis (EDA). It is used to create a grid of scatterplots (and optionally histograms or KDE plots on\n",
        "the diagonals) for visualizing pairwise relationships among numerical variables in a dataset.\n",
        "\n",
        "Key Features of pairplot()\n",
        " 1. Pairwise Relationships:\n",
        " • Displays scatterplots for all pairs of numerical variables in the dataset.\n",
        " • Shows how variables are correlated or distributed.\n",
        " 2. Diagonal Visualization:\n",
        " • On the diagonal, pairplot() typically displays univariate distributions of individual variables using histograms or kernel density estimates (KDE).\n",
        " 3. Categorical Hue:\n",
        " • Allows differentiation of data points based on a categorical variable using the hue parameter, assigning colors to different categories.\n",
        " 4. Customizability:\n",
        " • Supports customization of plots, such as marker styles, plot kinds (scatter or kde), and additional arguments for the underlying plotting functions.\n",
        "\n",
        "Why Use pairplot()?\n",
        " 1. Exploratory Data Analysis:\n",
        " • Quickly identify trends, patterns, and relationships between variables.\n",
        " • Detect potential outliers and clusters in the data.\n",
        " 2. Correlation Insights:\n",
        " • Assess the strength and direction of linear or nonlinear relationships between variables.\n",
        "\n",
        "How to Use pairplot()\n",
        "\n",
        "Basic Example\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load example dataset\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "# Create a pairplot\n",
        "sns.pairplot(iris)\n",
        "plt.show()\n",
        "\n",
        " • This creates scatterplots for all pairs of numerical columns in the iris dataset.\n",
        " • Histograms or KDE plots are displayed along the diagonal.\n",
        "\n",
        "Using the hue Parameter\n",
        "\n",
        "sns.pairplot(iris, hue=\"species\")\n",
        "plt.show()\n",
        "\n",
        " • hue=\"species\": Differentiates data points by the species column using colors.\n",
        " • Useful for visualizing how the relationships vary across categories.\n",
        "\n",
        "Changing the Diagonal Plot Type\n",
        "\n",
        "sns.pairplot(iris, diag_kind=\"kde\")\n",
        "plt.show()\n",
        "\n",
        " • diag_kind=\"kde\": Replaces histograms with kernel density estimates on the diagonal.\n",
        "\n",
        "Specifying Plot Types\n",
        "\n",
        "sns.pairplot(iris, kind=\"reg\")\n",
        "plt.show()\n",
        "\n",
        " • kind=\"reg\": Adds regression lines to the scatterplots for better trend visualization.\n",
        "\n",
        "Advantages of pairplot()\n",
        " 1. Quick and Comprehensive:\n",
        " • Generates a comprehensive visualization of pairwise relationships with minimal code.\n",
        " 2. Categorical Insights:\n",
        " • Provides an intuitive way to explore how categories affect numerical relationships.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Seaborn’s pairplot() function is an essential tool for EDA, helping analysts and data scientists quickly understand pairwise relationships, distributions, and category-level\n",
        " differences in numerical datasets. Its ease of use and versatility make it a go-to choice for initial data visualization.\n",
        "\n",
        "#12 What is the purpose of the describe() function in Pandas?\n",
        "* Purpose of the describe() Function in Pandas\n",
        "\n",
        "The describe() function in pandas is used to generate summary statistics for numerical and/or categorical data in a DataFrame or Series. It provides a quick overview\n",
        " of the distribution, central tendency, and variability of the data, making it a valuable tool for exploratory data analysis (EDA).\n",
        "\n",
        "Key Features of describe()\n",
        " 1. Summary Statistics for Numerical Data:\n",
        " • For numeric columns, it computes statistics such as:\n",
        " • Count: Number of non-missing values.\n",
        " • Mean: Average of the values.\n",
        " • Std: Standard deviation.\n",
        " • Min: Minimum value.\n",
        " • 25%, 50%, 75%: Percentiles (quartiles).\n",
        " • Max: Maximum value.\n",
        " 2. Summary for Categorical Data:\n",
        " • If applied to non-numerical (categorical or object-type) data, it computes:\n",
        " • Count: Number of non-missing values.\n",
        " • Unique: Number of unique values.\n",
        " • Top: Most frequent value.\n",
        " • Freq: Frequency of the top value.\n",
        " 3. Customizable:\n",
        " • You can specify whether to include only numerical, categorical, or all columns using the include and exclude parameters.\n",
        "\n",
        "Syntax\n",
        "\n",
        "DataFrame.describe(percentiles=None, include=None, exclude=None)\n",
        "\n",
        " • percentiles: Specifies custom percentiles to include (default: [0.25, 0.5, 0.75]).\n",
        " • include: Specifies data types to include in the summary (e.g., ['number', 'object'] or ['all']).\n",
        " • exclude: Specifies data types to exclude from the summary.\n",
        "\n",
        "Examples\n",
        "\n",
        "1. Summary Statistics for Numerical Data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 29],\n",
        "    'Salary': [50000, 60000, 75000, 80000, 67000],\n",
        "    'Department': ['HR', 'IT', 'Finance', 'HR', 'IT']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Generate summary statistics for numerical columns\n",
        "print(df.describe())\n",
        "\n",
        "Output:\n",
        "\n",
        "             Age       Salary\n",
        "count   5.000000      5.00000\n",
        "mean   31.800000  66400.00000\n",
        "std     5.981631  12137.19209\n",
        "min    25.000000  50000.00000\n",
        "25%    29.000000  60000.00000\n",
        "50%    30.000000  67000.00000\n",
        "75%    35.000000  75000.00000\n",
        "max    40.000000  80000.00000\n",
        "\n",
        "2. Summary for Categorical Data\n",
        "\n",
        "# Generate summary for categorical columns\n",
        "print(df.describe(include=['object']))\n",
        "\n",
        "Output:\n",
        "\n",
        "       Department\n",
        "count           5\n",
        "unique          3\n",
        "top             HR\n",
        "freq            2\n",
        "\n",
        "3. Summary for All Data Types\n",
        "\n",
        "# Include both numerical and categorical data\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "4. Custom Percentiles\n",
        "\n",
        "# Specify custom percentiles\n",
        "print(df.describe(percentiles=[0.1, 0.5, 0.9]))\n",
        "\n",
        "Conclusion\n",
        "\n",
        "The describe() function in pandas is a must-have tool for quickly summarizing data. It is especially useful during the initial stages of data analysis to gain insights into\n",
        " numerical and categorical variables, detect anomalies, and assess data distribution.\n",
        "\n",
        "#13 Why is handling missing data important in Pandas?\n",
        "* Importance of Handling Missing Data in Pandas\n",
        "\n",
        "Handling missing data is a critical step in data analysis and preprocessing because missing values can significantly impact the performance and reliability of data-driven models\n",
        " and decisions. Here’s why it’s essential:\n",
        "\n",
        "1. Ensuring Data Quality\n",
        " • Accuracy: Missing values can distort statistical summaries (e.g., mean, median) and lead to inaccurate insights.\n",
        " • Completeness: Incomplete data can misrepresent the dataset and affect downstream analyses.\n",
        "\n",
        "2. Preventing Errors in Analysis\n",
        " • Many algorithms (e.g., machine learning models, statistical methods) cannot handle missing values directly and may throw errors or fail to execute.\n",
        " • Missing values can propagate through calculations, causing unexpected results or inconsistencies.\n",
        "\n",
        "3. Preserving Model Performance\n",
        " • Models trained on datasets with missing data may fail to generalize well, leading to poor predictions.\n",
        " • Proper handling ensures that the remaining data is meaningful and reliable.\n",
        "\n",
        "4. Improving Data Interpretability\n",
        " • Identifying and addressing missing data provides a clearer understanding of patterns and relationships within the dataset.\n",
        "\n",
        "5. Avoiding Bias\n",
        " • Improper handling of missing data can introduce bias:\n",
        " • For example, deleting rows with missing values might disproportionately remove certain groups, leading to skewed results.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'A': [1, 2, None], 'B': [4, None, 6]})\n",
        "print(df.isnull())\n",
        "\n",
        "\n",
        " 2. Dropping Missing Data\n",
        " • Use .dropna() to remove rows or columns with missing values.\n",
        "\n",
        "df.dropna(axis=0)  # Drops rows with missing values\n",
        "\n",
        "\n",
        " 3. Filling Missing Data\n",
        " • Use .fillna() to replace missing values with a specified value (e.g., mean, median, or a constant).\n",
        "\n",
        "df['A'] = df['A'].fillna(df['A'].mean())  # Fill with mean\n",
        "\n",
        "\n",
        " 4. Interpolating Missing Data\n",
        " • Use .interpolate() to estimate missing values based on other data points.\n",
        "\n",
        "df['A'] = df['A'].interpolate()\n",
        "\n",
        "\n",
        " 5. Flagging Missing Data\n",
        " • Add an additional column to indicate where missing values were located before imputation.\n",
        "\n",
        "Impact of Mishandling Missing Data\n",
        " 1. Skewed Results:\n",
        " • Missing data can lead to biased conclusions if not handled properly.\n",
        " 2. Model Failures:\n",
        " • Models that cannot handle NaN values may crash or perform poorly.\n",
        " 3. Loss of Valuable Data:\n",
        " • Overzealous removal of rows/columns with missing data can lead to significant loss of information.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Handling missing data is crucial in pandas to ensure the integrity and reliability of your analysis. Proper techniques for\n",
        " managing missing values can minimize bias, improve model performance, and provide more accurate and meaningful insights from the data.\n",
        "\n",
        "#14 What are the benefits of using Plotly for data visualization?\n",
        "* Benefits of Using Plotly for Data Visualizations\n",
        "\n",
        "Plotly is a powerful library for creating interactive and visually appealing data visualizations. It is widely used in data science, analytics, and web development due to its versatility and ease of use. Below are the key benefits of using Plotly:\n",
        "\n",
        "1. Interactivity\n",
        " • Dynamic Features: Plotly allows users to interact with visualizations through zooming, panning, hovering, and selecting data points.\n",
        " • Customizable Tooltips: Tooltips display detailed information about data points, improving user experience and data exploration.\n",
        " • Drill-Down Capability: Users can explore data at deeper levels without creating additional plots.\n",
        "\n",
        "2. Wide Range of Visualization Types\n",
        " • Plotly supports a variety of visualization types, such as:\n",
        " • Basic charts: Line, bar, scatter, pie.\n",
        " • Advanced charts: Box plots, heatmaps, 3D plots, choropleths, and more.\n",
        " • Specialized charts: Financial charts, time series, and network diagrams.\n",
        " • This versatility makes it suitable for different domains like business, science, and engineering.\n",
        "\n",
        "3. High-Quality Visuals\n",
        " • Publication-Ready Graphics: Plotly creates polished and professional-quality visuals.\n",
        " • Responsive Design: Visualizations adapt to various screen sizes, making them suitable for web applications.\n",
        " • Customization Options: Nearly every aspect of a plot can be customized, including colors, fonts, labels, and layout.\n",
        "\n",
        "4. Support for Multiple Programming Languages\n",
        " • Plotly integrates seamlessly with several programming languages, including:\n",
        " • Python (Plotly.py)\n",
        " • R (Plotly R)\n",
        " • JavaScript (Plotly.js)\n",
        " • Julia and MATLAB\n",
        " • This cross-language compatibility makes it accessible to a wide range of users.\n",
        "\n",
        "5. Built-In Dash Integration\n",
        " • Plotly is the foundation of Dash, a Python framework for creating interactive web applications.\n",
        " • Dash allows users to build dashboards with Plotly visualizations, providing interactivity and integration with live data.\n",
        "\n",
        "6. Ease of Use\n",
        " • High-Level API: Plotly’s API simplifies the creation of complex plots with minimal code.\n",
        " • Integration with Pandas: Directly pass Pandas DataFrames for quick and easy plotting.\n",
        " • Declarative Syntax: Users can describe the structure of a plot intuitively.\n",
        "\n",
        "7. 3D Visualization\n",
        " • Plotly offers robust 3D plotting capabilities, such as 3D scatter plots, surface plots, and 3D mesh plots.\n",
        " • These visualizations are interactive, allowing users to rotate and zoom for better understanding.\n",
        "\n",
        "Comparison with Other Libraries\n",
        "\n",
        "Feature Plotly Matplotlib Seaborn\n",
        "Interactivity Yes No Limited\n",
        "3D Visualization Yes Limited No\n",
        "Ease of Use High (intuitive API) Moderate High (built on Matplotlib)\n",
        "Customization Extensive Extensive Moderate\n",
        "Real-Time Data Supported Not supported Not supported\n",
        "\n",
        "When to Use Plotly\n",
        " • Interactive Dashboards: Ideal for creating interactive and engaging dashboards for web or business applications.\n",
        " • Exploratory Data Analysis (EDA): Use it for detailed data exploration with interactive tools.\n",
        " • Complex Visualizations: Perfect for 3D plots, geospatial maps, and multi-dimensional datasets.\n",
        " • Web Applications: Combine with Dash for dynamic web-based data visualizations.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "#15 How does NumPy handle multidimensional arrays?\n",
        "* How NumPy Handles Multidimensional Arrays\n",
        "\n",
        "NumPy is specifically designed to efficiently handle multidimensional arrays, also known as ndarrays (short for N-dimensional arrays).\n",
        " These arrays are the foundation of NumPy and provide capabilities for storing and manipulating numerical data of any dimension. Here’s how NumPy manages multidimensional arrays:\n",
        "\n",
        "1. N-Dimensional Array Structure\n",
        " • Definition: A NumPy array can have one or more dimensions (1D, 2D, 3D, etc.).\n",
        " • Shape: The shape of an array is a tuple that defines the size along each dimension. For example:\n",
        " • A 2D array with 3 rows and 4 columns has a shape (3, 4).\n",
        " • A 3D array with dimensions 2x3x4 has a shape (2, 3, 4).\n",
        "\n",
        "Example:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Creating a 2D array\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(array_2d.shape)  # Output: (2, 3)\n",
        "\n",
        "# Creating a 3D array\n",
        "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(array_3d.shape)  # Output: (2, 2, 2)\n",
        "\n",
        "2. Efficient Storage and Operations\n",
        " • Homogeneous Data: All elements in a NumPy array must be of the same data type, which allows for efficient memory usage and computation.\n",
        " • Contiguous Memory: Arrays are stored in contiguous memory locations, enabling fast access and operations compared to Python lists.\n",
        "\n",
        "3. Broadcasting in Multidimensional Arrays\n",
        " • NumPy uses broadcasting to perform element-wise operations on arrays of different shapes, without the need for explicit looping.\n",
        " • The smaller array is “broadcast” to match the shape of the larger array.\n",
        "\n",
        "Example:\n",
        "\n",
        "a = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
        "b = np.array([1, 2, 3])               # Shape: (3,)\n",
        "result = a + b  # Broadcasting adds b to each row of a\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "[[ 2  4  6]\n",
        " [ 5  7  9]]\n",
        "\n",
        "4. Indexing and Slicing\n",
        " • Multidimensional arrays can be indexed and sliced along any dimension to extract or modify data.\n",
        "\n",
        "Example:\n",
        "\n",
        "array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Accessing an element\n",
        "print(array[1, 2])  # Output: 6 (element at 2nd row, 3rd column)\n",
        "\n",
        "# Slicing\n",
        "print(array[:, 1])  # Output: [2 5 8] (all rows, 2nd column)\n",
        "\n",
        "5. Reshaping Arrays\n",
        " • NumPy provides the ability to reshape arrays, changing their dimensions without altering the data.\n",
        "\n",
        "Example:\n",
        "\n",
        "array = np.array([1, 2, 3, 4, 5, 6])\n",
        "reshaped_array = array.reshape(2, 3)\n",
        "print(reshaped_array)\n",
        "\n",
        "Output:\n",
        "\n",
        "[[1 2 3]\n",
        " [4 5 6]]\n",
        "\n",
        "6. Mathematical Operations\n",
        " • NumPy supports a wide range of element-wise and matrix operations on multidimensional arrays:\n",
        " • Arithmetic Operations: +, -, *, /\n",
        " • Aggregations: sum(), mean(), max(), etc.\n",
        " • Linear Algebra: dot(), matmul(), etc.\n",
        "\n",
        "Example:\n",
        "\n",
        "array = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Element-wise multiplication\n",
        "print(array * 2)\n",
        "\n",
        "# Sum along a dimension\n",
        "print(array.sum(axis=0))  # Sum along rows\n",
        "\n",
        "7. Masking and Boolean Indexing\n",
        " • NumPy allows the use of boolean conditions to filter or mask elements in multidimensional arrays.\n",
        "\n",
        "Example:\n",
        "\n",
        "array = np.array([[1, 2], [3, 4]])\n",
        "mask = array > 2\n",
        "print(array[mask])  # Output: [3 4]\n",
        "\n",
        "8. Flexibility with Higher Dimensions\n",
        " • NumPy efficiently handles arrays with more than two dimensions (3D, 4D, etc.), commonly used in fields like:\n",
        " • Data Science: Multidimensional datasets.\n",
        " • Image Processing: Color images (3D arrays: width × height × color channels).\n",
        " • Machine Learning: High-dimensional tensors.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Creating a 3D array\n",
        "array_3d = np.random.rand(2, 3, 4)  # Shape: (2, 3, 4)\n",
        "print(array_3d)\n",
        "\n",
        "Advantages of NumPy Multidimensional Arrays\n",
        " 1. Performance:\n",
        " • Operations on NumPy arrays are faster than Python lists due to optimized C-based implementation.\n",
        " 2. Memory Efficiency:\n",
        " • Arrays use less memory compared to equivalent data structures in Python.\n",
        " 3. Convenience:\n",
        " • Powerful features like broadcasting, slicing, and reshaping simplify complex operations.\n",
        " 4. Scalability:\n",
        " • Supports large-scale multidimensional data for advanced use cases in machine learning, physics, and more.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "NumPy handles multidimensional arrays with efficiency, flexibility, and simplicity Its ndarray structure, combined with powerful operations like broadcasting,\n",
        " indexing, and mathematical functions, makes it an essential library for numerical computing and scientific applications.\n",
        "\n",
        "#16 What is the role of Bokeh in data visualization?\n",
        " * The Role of Bokeh in Data Visualization\n",
        "\n",
        "Bokeh is a powerful Python library designed for interactive and scalable visualizations. It bridges the gap between static plotting libraries\n",
        " (e.g., Matplotlib) and web-based visualization tools (e.g., D3.js) by providing an easy-to-use Python interface for creating web-ready, interactive visualizations.\n",
        "  Here’s how Bokeh plays a role in data visualization:\n",
        "\n",
        "1. Interactive Visualizations\n",
        " • Bokeh enables users to create interactive visualizations with features like:\n",
        " • Zooming: Allows users to zoom into specific areas of a plot.\n",
        " • Panning: Enables navigation through the visualization.\n",
        " • Hover Tool: Displays additional information about data points on hover.\n",
        " • Custom Widgets: Includes sliders, buttons, and dropdowns for dynamic control of plots.\n",
        "\n",
        "2. Web-Ready Visualizations\n",
        " • Bokeh generates HTML and JavaScript under the hood, allowing users to embed interactive plots directly into web applications without requiring additional frameworks.\n",
        " • Visualizations can be shared via standalone HTML files or deployed on platforms like Flask, Django, or Bokeh Server.\n",
        "\n",
        "3. High-Level and Low-Level Interfaces\n",
        "\n",
        "Bokeh provides two main levels of control:\n",
        " 1. High-Level Interface:\n",
        " • Simplifies common plotting tasks.\n",
        " • Example: bokeh.plotting for creating quick and interactive visualizations.\n",
        " 2. Low-Level Interface:\n",
        " • Gives detailed control over visual elements.\n",
        " • Example: bokeh.models for advanced customization.\n",
        "\n",
        "4. Handling Large Datasets\n",
        " • Bokeh efficiently visualizes large datasets with tools like data streaming and downsampling.\n",
        " • Integrates with data structures such as Pandas DataFrames, NumPy arrays, and even databases.\n",
        "\n",
        "5. Versatile Chart Options\n",
        " • Bokeh supports a wide range of plot types:\n",
        " • Basic plots: Line, scatter, bar, pie.\n",
        " • Advanced plots: Heatmaps, geospatial maps, network graphs.\n",
        " • Statistical plots: Box plots, histograms.\n",
        "\n",
        "6. Customization\n",
        " • Offers extensive customization of visual elements, including:\n",
        " • Colors, fonts, and themes.\n",
        " • Axes, legends, and annotations.\n",
        " • Layouts with multiple subplots and linked interactions.\n",
        "\n",
        "7. Integration with Other Tools\n",
        " • Pandas: Simplifies data manipulation and direct plotting from DataFrames.\n",
        " • NumPy: Efficiently handles numerical data for plotting.\n",
        " • Jupyter Notebooks: Provides inline interactive visualizations.\n",
        " • Databases: Supports real-time data visualization by connecting directly to SQL databases or data streaming sources.\n",
        "\n",
        "Use Cases for Bokeh\n",
        " 1. Exploratory Data Analysis:\n",
        " • Ideal for creating interactive plots that allow users to explore datasets dynamically.\n",
        " 2. Web-Based Dashboards:\n",
        " • Build interactive dashboards for business applications, monitoring systems, or data storytelling.\n",
        " 3. Real-Time Monitoring:\n",
        " • Visualize live data streams, such as stock prices or IoT sensor data.\n",
        " 4. Data Storytelling:\n",
        " • Create visually appealing narratives with interactive elements to engage audiences.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Bokeh plays a pivotal role in data visualization by combining interactivity, scalability, and web integration. Its ability to handle large datasets, create real-time\n",
        " visualizations, and integrate seamlessly with Python’s data ecosystem makes it a versatile tool for data scientists, analysts, and developers.\n",
        "\n",
        "#17 Explain the difference between apply() and map() in Pandas?\n",
        "* Difference Between apply() and map() in Pandas\n",
        "\n",
        "Both apply() and map() are functions in Pandas that allow you to apply operations to data in a DataFrame or Series. However, they are used in different contexts and have\n",
        " distinct functionalities.\n",
        "\n",
        "1. apply() Function\n",
        " • Purpose: The apply() function applies a function along an axis (rows or columns) of a DataFrame or to the entire Series.\n",
        " • Usage: Works with both DataFrames and Series.\n",
        " • Flexibility: Can handle functions that operate on entire rows, columns, or individual elements.\n",
        " • Input: A function (built-in, user-defined, or lambda) that operates on rows, columns, or elements.\n",
        "\n",
        "Example with Series:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Applying a function to a Series\n",
        "s = pd.Series([1, 2, 3, 4])\n",
        "result = s.apply(lambda x: x**2)\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "0     1\n",
        "1     4\n",
        "2     9\n",
        "3    16\n",
        "dtype: int64\n",
        "\n",
        "Example with DataFrame:\n",
        "\n",
        "# Applying a function to a DataFrame\n",
        "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
        "result = df.apply(lambda x: x.sum(), axis=0)  # Sum each column\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "A     6\n",
        "B    15\n",
        "dtype: int64\n",
        "\n",
        "2. map() Function\n",
        " • Purpose: The map() function applies a function element-wise to a Series.\n",
        " • Usage: Only works with Pandas Series (not DataFrames).\n",
        " • Input: A function, dictionary, or Series to map values to corresponding outputs.\n",
        "\n",
        "Example with a Function:\n",
        "\n",
        "# Applying a function to a Series\n",
        "s = pd.Series([1, 2, 3, 4])\n",
        "result = s.map(lambda x: x**2)\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "0     1\n",
        "1     4\n",
        "2     9\n",
        "3    16\n",
        "dtype: int64\n",
        "\n",
        "Example with a Dictionary:\n",
        "\n",
        "# Mapping values using a dictionary\n",
        "s = pd.Series(['cat', 'dog', 'mouse'])\n",
        "result = s.map({'cat': 'feline', 'dog': 'canine'})\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "0    feline\n",
        "1    canine\n",
        "2       NaN\n",
        "dtype: object\n",
        "\n",
        "Example with a Series:\n",
        "\n",
        "# Mapping values using another Series\n",
        "mapping = pd.Series({'cat': 'feline', 'dog': 'canine'})\n",
        "result = s.map(mapping)\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "0    feline\n",
        "1    canine\n",
        "2       NaN\n",
        "dtype: object\n",
        "\n",
        "Key Differences Between apply() and map()\n",
        "\n",
        "Feature apply() map()\n",
        "Applicable To DataFrames and Series Only Series\n",
        "Functionality Operates on rows/columns (DataFrame) or elements (Series). Operates element-wise.\n",
        "Input Types Functions (built-in, custom, or lambda). Functions, dictionaries, or Series.\n",
        "Axis Argument Can specify axis=0 (columns) or axis=1 (rows) for DataFrame. No axis argument, works element-wise.\n",
        "Use Case Apply complex row/column-wise operations on DataFrames. Element-wise transformations or lookups.\n",
        "\n",
        "When to Use apply() vs map()\n",
        "\n",
        "Scenario Function to Use\n",
        "Element-wise transformation on a Series. map()\n",
        "Applying a function to rows/columns in a DataFrame. apply()\n",
        "Applying a dictionary or Series for mapping. map()\n",
        "Need flexibility for operations beyond element-wise. apply()\n",
        "\n",
        "Conclusion\n",
        " • Use apply() for complex row- or column-wise operations in a DataFrame or when applying a function to an entire Series.\n",
        " • Use map() for element-wise operations or value mappings in a Series.\n",
        "\n",
        "#18 What are some advanced features of NumPy?\n",
        "*Advanced Features of NumPy\n",
        "\n",
        "NumPy offers many advanced features that go beyond basic array operations, making it a powerful tool for scientific computing, data analysis, and machine learning.\n",
        " Below are some of its most notable advanced features:\n",
        "\n",
        "1. Broadcasting\n",
        " • Description: Enables arithmetic operations on arrays of different shapes by automatically expanding smaller arrays to match the shape of the larger one.\n",
        " • Use Case: Simplifies operations without explicit looping or reshaping.\n",
        "\n",
        "Example:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])  # Shape: (3,)\n",
        "b = np.array([[10], [20]])  # Shape: (2, 1)\n",
        "\n",
        "result = a + b  # Broadcasting: b is expanded to match a\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "[[11 12 13]\n",
        " [21 22 23]]\n",
        "\n",
        "2. Universal Functions (ufuncs)\n",
        " • Description: Fast, element-wise operations that support broadcasting, type casting, and more.\n",
        " • Examples: np.add(), np.multiply(), np.sin(), np.exp(), etc.\n",
        " • Use Case: Perform mathematical operations on arrays efficiently.\n",
        "\n",
        "Example:\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "result = np.exp(a)  # Element-wise exponential\n",
        "print(result)\n",
        "\n",
        "3. Advanced Indexing\n",
        " • Description: NumPy allows indexing arrays using slices, boolean masks, or arrays of indices for advanced data selection and manipulation.\n",
        " • Use Case: Extract or modify data based on complex conditions.\n",
        "\n",
        "Example:\n",
        "\n",
        "a = np.array([10, 20, 30, 40])\n",
        "indices = [0, 2]\n",
        "result = a[indices]  # Select elements at indices 0 and 2\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "[10 30]\n",
        "\n",
        "4. Linear Algebra Module\n",
        " • Description: Provides functions for matrix operations, solving linear systems, eigenvalue decomposition, singular value decomposition, and more.\n",
        " • Use Case: Essential for scientific computing and machine learning.\n",
        "\n",
        "Example:\n",
        "\n",
        "from numpy.linalg import inv, det\n",
        "\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "print(inv(A))  # Inverse of matrix A\n",
        "print(det(A))  # Determinant of matrix A\n",
        "\n",
        "5. Random Sampling\n",
        " • Description: numpy.random provides tools for generating random numbers, creating random distributions, and reproducible sampling.\n",
        " • Use Case: Simulations, machine learning, and statistical modeling.\n",
        "\n",
        "Example:\n",
        "\n",
        "from numpy.random import normal, randint\n",
        "\n",
        "rand_array = normal(0, 1, (2, 3))  # Random values from a normal distribution\n",
        "print(rand_array)\n",
        "\n",
        "random_ints = randint(1, 10, 5)  # 5 random integers between 1 and 10\n",
        "print(random_ints)\n",
        "\n",
        "6. Memory Efficiency with Views and Copies\n",
        " • Description: NumPy distinguishes between views (shallow copies) and deep copies to optimize memory usage.\n",
        " • Use Case: Efficient handling of large datasets.\n",
        "\n",
        "Example:\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = a.view()  # View shares data with a\n",
        "b[0] = 99\n",
        "print(a)  # Changes in b affect a\n",
        "\n",
        "7. Broadcasting with Outer Products\n",
        " • Description: Compute the “outer product” of two vectors using broadcasting for advanced array manipulation.\n",
        "\n",
        "Example:\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5])\n",
        "result = np.outer(a, b)  # Outer product\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "[[ 4  5]\n",
        " [ 8 10]\n",
        " [12 15]]\n",
        "\n",
        "8. Structured Arrays\n",
        " • Description: Arrays that allow heterogeneous data types, similar to a database table or a structured record.\n",
        " • Use Case: Manage complex datasets with multiple fields.\n",
        "\n",
        "Example:\n",
        "\n",
        "data = np.array([(1, 'Alice', 25), (2, 'Bob', 30)],\n",
        "                dtype=[('ID', 'i4'), ('Name', 'U10'), ('Age', 'i4')])\n",
        "print(data['Name'])  # Access the 'Name' column\n",
        "\n",
        "#19 How does Pandas simplify time series analysis ?\n",
        "*How Pandas Simplifies Time Series Analysis\n",
        "\n",
        "Pandas provides robust support for time series data, making it a powerful tool for analyzing, manipulating, and visualizing temporal datasets. Below are the key ways Pandas\n",
        " simplifies time series analysis:\n",
        "\n",
        "1. Handling DateTime Data\n",
        " • Conversion to Datetime Objects: Pandas provides the pd.to_datetime() function to easily convert strings or other formats into datetime objects.\n",
        " • Indexing with DateTime: DateTimeIndex allows time-based indexing for efficient slicing and filtering.\n",
        "\n",
        "Example:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Converting strings to datetime\n",
        "dates = ['2023-01-01', '2023-01-02', '2023-01-03']\n",
        "datetime_series = pd.to_datetime(dates)\n",
        "print(datetime_series)\n",
        "\n",
        "# Creating a DataFrame with a DateTimeIndex\n",
        "data = {'value': [10, 20, 30]}\n",
        "df = pd.DataFrame(data, index=datetime_series)\n",
        "print(df)\n",
        "\n",
        "2. Resampling\n",
        " • Description: Aggregate or transform data to a different frequency (e.g., daily to monthly, hourly to weekly).\n",
        " • Functions: resample() for time-based groupings, with methods like .mean(), .sum(), etc.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Resampling to a monthly frequency\n",
        "df = pd.DataFrame({'value': [10, 20, 30, 40]},\n",
        "                  index=pd.date_range('2023-01-01', periods=4, freq='D'))\n",
        "monthly = df.resample('M').mean()\n",
        "print(monthly)\n",
        "\n",
        "3. Shifting and Lagging\n",
        " • Description: Shift data backward or forward in time to calculate changes or create lagged features.\n",
        " • Functions: shift() for time-shifting and diff() for calculating differences.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Creating lagged data\n",
        "df['shifted'] = df['value'].shift(1)\n",
        "df['difference'] = df['value'].diff(1)\n",
        "print(df)\n",
        "\n",
        "4. Date Range Generation\n",
        " • Description: Generate sequences of dates with specific frequencies using pd.date_range().\n",
        " • Use Case: Create time-based indexes or simulate time series data.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Generating a daily date range\n",
        "date_range = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
        "print(date_range)\n",
        "\n",
        "5. Handling Missing Data in Time Series\n",
        " • Description: Fill or interpolate missing time points.\n",
        " • Functions:\n",
        " • ffill() (forward fill) and bfill() (backward fill).\n",
        " • interpolate() for linear or spline-based interpolation.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Handling missing values\n",
        "df.loc['2023-01-03', 'value'] = None  # Introduce a missing value\n",
        "df['filled'] = df['value'].fillna(method='ffill')\n",
        "print(df)\n",
        "\n",
        "6. Time-Based Filtering\n",
        " • Description: Filter data based on specific date ranges or conditions.\n",
        " • Use Case: Extract subsets of time series data for analysis.\n",
        "\n",
        "Example:\n",
        "\n",
        "# Filtering for a specific date range\n",
        "filtered = df['2023-01-01':'2023-01-02']\n",
        "print(filtered)\n",
        "\n",
        " Conclusion\n",
        "\n",
        "Pandas simplifies time series analysis by offering tools to manipulate, aggregate, and visualize temporal data. Its powerful datetime support, resampling capabilities,\n",
        " and integration with other Python libraries make it an essential tool for time series analytics.\n",
        "\n",
        "#20 What is the role of a pivot table in Pandas ?\n",
        "\n",
        "*  Role of a Pivot Table in Pandas\n",
        "\n",
        "A pivot table in Pandas is a powerful tool for summarizing, reorganizing, and aggregating data in a tabular format. It is particularly useful when analyzing and exploring\n",
        " datasets with multiple categorical and numerical variables.\n",
        "\n",
        "Key Roles and Use Cases of Pivot Tables in Pandas\n",
        "\n",
        "1. Data Summarization\n",
        " • Pivot tables provide a way to summarize and aggregate data across one or more categorical variables.\n",
        " • You can calculate statistics like mean, sum, count, max, min, etc., for numerical values grouped by categories.\n",
        "\n",
        "Example:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Department': ['HR', 'IT', 'HR', 'IT', 'Finance'],\n",
        "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Salary': [50000, 60000, 55000, 70000, 65000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table summarizing average salary by department\n",
        "pivot = pd.pivot_table(df, values='Salary', index='Department', aggfunc='mean')\n",
        "print(pivot)\n",
        "\n",
        "Output:\n",
        "\n",
        "            Salary\n",
        "Department\n",
        "Finance   65000.0\n",
        "HR        52500.0\n",
        "IT        65000.0\n",
        "\n",
        "2. Reshaping Data\n",
        " • Pivot tables allow you to reshape data by converting long-format data into a more readable and structured wide-format.\n",
        " • Rows and columns can be organized using categorical variables, making it easier to understand relationships in the data.\n",
        "\n",
        "Example:\n",
        "\n",
        "data = {\n",
        "    'Month': ['Jan', 'Jan', 'Feb', 'Feb'],\n",
        "    'Product': ['A', 'B', 'A', 'B'],\n",
        "    'Sales': [200, 300, 250, 400]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Reshaping data using a pivot table\n",
        "pivot = pd.pivot_table(df, values='Sales', index='Month', columns='Product', aggfunc='sum')\n",
        "print(pivot)\n",
        "\n",
        "Output:\n",
        "\n",
        "Product      A      B\n",
        "Month\n",
        "Jan       200.0  300.0\n",
        "Feb       250.0  400.0\n",
        "\n",
        "3. Grouped Calculations\n",
        " • Pivot tables allow for grouped calculations based on one or more categorical variables.\n",
        " • You can use multiple aggregations (e.g., mean and sum) to gain deeper insights.\n",
        "\n",
        "Example:\n",
        "\n",
        "pivot = pd.pivot_table(df, values='Sales', index='Month', columns='Product', aggfunc=['mean', 'sum'])\n",
        "print(pivot)\n",
        "\n",
        "4. Handling Missing Data\n",
        " • Pivot tables automatically handle missing data by filling in missing values with NaN or a specified default value using the fill_value parameter.\n",
        "\n",
        "Example:\n",
        "\n",
        "pivot = pd.pivot_table(df, values='Sales', index='Month', columns='Product', aggfunc='sum', fill_value=0)\n",
        "print(pivot)\n",
        "\n",
        "Output:\n",
        "\n",
        "Product      A      B\n",
        "Month\n",
        "Jan       200.0  300.0\n",
        "Feb       250.0  400.0\n",
        "\n",
        "5. Multi-Level Aggregation\n",
        " • Pivot tables support multi-level indexing (hierarchical indexing), allowing you to analyze data across multiple dimensions.\n",
        "\n",
        "Example:\n",
        "\n",
        "pivot = pd.pivot_table(df, values='Sales', index=['Month', 'Product'], aggfunc='sum')\n",
        "print(pivot)\n",
        "\n",
        "Output:\n",
        "\n",
        "                  Sales\n",
        "Month Product\n",
        "Jan   A          200.0\n",
        "      B          300.0\n",
        "Feb   A          250.0\n",
        "      B          400.0\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Pandas pivot tables are a versatile tool for data summarization, reshaping, and analysis. They simplify complex data operations by providing a concise and structured\n",
        " view of the data, enabling users to extract insights quickly.\n",
        "\n",
        "#21 Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "* Why is NumPy Array Slicing Faster than Python List Slicing?\n",
        "\n",
        "The primary reason NumPy array slicing is faster than Python list slicing lies in how data is stored and accessed in memory and the efficiency of NumPy’s underlying implementation. Here are the main reasons:\n",
        "\n",
        "1. Contiguous Memory Layout\n",
        " • NumPy arrays are stored in contiguous blocks of memory, meaning all elements are laid out sequentially in a fixed-size format (e.g., integers, floats) in RAM.\n",
        " • Python lists, on the other hand, are collections of pointers to objects stored in random locations in memory. Each element of a Python list is a reference to a Python object, which adds an extra layer of indirection.\n",
        "\n",
        "Implications:\n",
        " • Accessing a NumPy array slice is faster because the elements are located sequentially, enabling optimized memory access patterns (e.g., vectorized instructions, cache-friendly).\n",
        " • Python lists require dereferencing pointers for each element, slowing down operations.\n",
        "\n",
        "2. No Type Overhead in NumPy Arrays\n",
        " • NumPy arrays are homogeneous: all elements have the same data type (e.g., all integers or all floats).\n",
        " • Python lists are heterogeneous: elements can have different data types, requiring additional checks for type information during slicing.\n",
        "\n",
        "Implications:\n",
        " • NumPy performs slicing and other operations without checking data types repeatedly, resulting in faster execution.\n",
        " • Python lists must handle type variability, leading to additional overhead.\n",
        "\n",
        "3. Lazy View Creation in NumPy\n",
        " • Slicing a NumPy array creates a view of the original data rather than copying it. The view is essentially a new array object that references the same data in memory.\n",
        " • Slicing a Python list creates a new list that holds references to the sliced elements, incurring the cost of copying and creating a new object.\n",
        "\n",
        "Example:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# NumPy slicing: No copying, creates a view\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "slice_arr = arr[1:4]\n",
        "slice_arr[0] = 99  # Modifies original array\n",
        "print(arr)  # Output: [ 1 99  3  4  5]\n",
        "\n",
        "# Python list slicing: Creates a copy\n",
        "py_list = [1, 2, 3, 4, 5]\n",
        "slice_list = py_list[1:4]\n",
        "slice_list[0] = 99\n",
        "print(py_list)  # Output: [1, 2, 3, 4, 5]\n",
        "\n",
        "Implications:\n",
        " • In NumPy, slicing avoids the time and memory overhead of copying, making it faster.\n",
        " • Python lists require copying the slice into a new list, which is slower.\n",
        "\n",
        "4. Optimized Implementation in C\n",
        " • NumPy is implemented in C, allowing it to take advantage of low-level optimizations like:\n",
        " • Vectorized operations.\n",
        " • Loop unrolling.\n",
        " • Use of hardware-specific optimizations (e.g., SIMD instructions).\n",
        " • Python lists are implemented in pure Python, which does not leverage such low-level optimizations.\n",
        "\n",
        "Implications:\n",
        " • NumPy slicing and other operations are significantly faster because they rely on highly optimized C code.\n",
        " • Python list slicing operates within the constraints of Python’s higher-level abstraction.\n",
        "\n",
        "5. Reduced Overhead for Large Data\n",
        " • NumPy arrays are specifically designed for handling large numerical datasets efficiently. They minimize overhead by focusing on fixed-size, contiguous storage.\n",
        " • Python lists are generic data structures, not optimized for numerical computations or large datasets.\n",
        "\n",
        "Implications:\n",
        " • The performance difference becomes more pronounced as the size of the data grows.\n",
        " • For large arrays, NumPy slicing is orders of magnitude faster.\n",
        "\n",
        "Performance Comparison\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# NumPy array slicing\n",
        "arr = np.arange(10**6)\n",
        "start = time.time()\n",
        "slice_arr = arr[:500000]\n",
        "end = time.time()\n",
        "print(f\"NumPy slicing time: {end - start:.6f} seconds\")\n",
        "\n",
        "# Python list slicing\n",
        "py_list = list(range(10**6))\n",
        "start = time.time()\n",
        "slice_list = py_list[:500000]\n",
        "end = time.time()\n",
        "print(f\"Python list slicing time: {end - start:.6f} seconds\")\n",
        "\n",
        "Sample Output:\n",
        "\n",
        "NumPy slicing time: 0.000002 seconds\n",
        "Python list slicing time: 0.002587 seconds\n",
        "\n",
        "Conclusion\n",
        "\n",
        "NumPy array slicing is faster than Python list slicing because of its contiguous memory layout, reduced type overhead, lazy view creation, and optimized low-level implementation.\n",
        "For numerical computations and handling large datasets, NumPy is significantly more efficient than Python lists.\n",
        "\n",
        "#22 What are some common use cases for Seaborn?\n",
        "* Common Use Cases for Seaborn\n",
        "\n",
        "Seaborn is a Python data visualization library built on top of Matplotlib. It is widely used for creating attractive, informative, and statistical visualizations. Below are some common use cases:\n",
        "\n",
        "1. Exploratory Data Analysis (EDA)\n",
        " • Seaborn is often used to visually explore datasets, helping analysts understand data distributions, relationships, and patterns.\n",
        " • Common plots for EDA:\n",
        " • Histograms (sns.histplot): To visualize the distribution of a single variable.\n",
        " • Box plots (sns.boxplot): To identify outliers and data spread.\n",
        " • Pair plots (sns.pairplot): To explore pairwise relationships in datasets.\n",
        "\n",
        "Example:\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import load_dataset\n",
        "\n",
        "data = load_dataset('tips')\n",
        "sns.pairplot(data)\n",
        "plt.show()\n",
        "\n",
        "2. Visualizing Statistical Relationships\n",
        " • Seaborn provides built-in functions to visualize relationships between two or more variables.\n",
        " • Common plots:\n",
        " • Scatter plots (sns.scatterplot): For relationships between two numerical variables.\n",
        " • Line plots (sns.lineplot): For trends over time or continuous variables.\n",
        " • Regression plots (sns.regplot and sns.lmplot): To visualize linear regression and its confidence intervals.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.scatterplot(data=data, x=\"total_bill\", y=\"tip\", hue=\"smoker\")\n",
        "plt.show()\n",
        "\n",
        "3. Analyzing Categorical Data\n",
        " • Seaborn excels in visualizing categorical variables and their relationships with numerical variables.\n",
        " • Common plots:\n",
        " • Bar plots (sns.barplot): Show aggregated values (e.g., mean) for categories.\n",
        " • Count plots (sns.countplot): Show frequency distribution of categories.\n",
        " • Violin plots (sns.violinplot): Show distributions split by categories.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.barplot(data=data, x=\"day\", y=\"total_bill\", hue=\"sex\")\n",
        "plt.show()\n",
        "\n",
        "4. Visualizing Data Distributions\n",
        " • Seaborn makes it easy to plot and compare data distributions.\n",
        " • Common plots:\n",
        " • Histograms and KDE plots (sns.histplot, sns.kdeplot): Show data distribution with optional density estimation.\n",
        " • Rug plots (sns.rugplot): Add marginal tick marks to other plots for detailed distribution.\n",
        " • Joint plots (sns.jointplot): Combine scatter plots and histograms/KDE plots.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.histplot(data=data, x=\"total_bill\", kde=True, hue=\"sex\")\n",
        "plt.show()\n",
        "\n",
        "5. Heatmaps for Correlation and Matrix Data\n",
        " • Heatmaps are commonly used to visualize correlations, confusion matrices, or any matrix-like data.\n",
        " • Correlation Heatmaps: Summarize relationships between numerical variables.\n",
        "\n",
        "Example:\n",
        "\n",
        "correlation_matrix = data.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()\n",
        "\n",
        "6. Time Series Analysis\n",
        " • Seaborn can be used to analyze and visualize time series data with line plots.\n",
        " • Common use: Highlight trends, seasonality, and outliers.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.lineplot(data=data, x=\"size\", y=\"total_bill\", hue=\"day\")\n",
        "plt.show()\n",
        "\n",
        "7. Highlighting Subgroups in Data\n",
        " • Seaborn supports color-coding and faceting for visualizing subgroups.\n",
        " • Common plots:\n",
        " • Hue parameter: Color-code data based on categorical variables.\n",
        " • Facet grids (sns.FacetGrid): Create multiple subplots for subgroups.\n",
        "\n",
        "Example:\n",
        "\n",
        "g = sns.FacetGrid(data, col=\"sex\", row=\"smoker\")\n",
        "g.map(sns.scatterplot, \"total_bill\", \"tip\")\n",
        "plt.show()\n",
        "\n",
        "8. Advanced Statistical Visualizations\n",
        " • Seaborn simplifies creating advanced visualizations with a statistical focus.\n",
        " • Common plots:\n",
        " • Cluster maps (sns.clustermap): For hierarchical clustering.\n",
        " • Strip plots (sns.stripplot): Overlay categorical data on other plots.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.clustermap(correlation_matrix, cmap=\"coolwarm\", annot=True)\n",
        "plt.show()\n",
        "\n",
        "9. Customizing and Enhancing Plots\n",
        " • Seaborn’s themes and styles make plots more aesthetically pleasing and customizable.\n",
        " • Built-in themes like darkgrid, whitegrid, dark, and ticks enhance readability.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.boxplot(data=data, x=\"day\", y=\"total_bill\", hue=\"sex\")\n",
        "plt.show()\n",
        "\n",
        "10. Quick Visualizations for Built-in Datasets\n",
        " • Seaborn includes several built-in datasets (e.g., tips, iris, penguins) for quick prototyping and exploration.\n",
        "\n",
        "Example\n",
        "\n",
        "data = sns.load_dataset(\"penguins\")\n",
        "sns.pairplot(data, hue=\"species\")\n",
        "plt.show()\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Seaborn is a versatile library that simplifies statistical visualization, making it ideal for exploratory data analysis, distribution analysis, and categorical comparisons.\n",
        " It enhances Matplotlib with more attractive, customizable, and statistical plots, making it a go-to tool for data scientists and analysts.\n",
        "\n",
        "\n",
        " #8                                                 Practical\n",
        "\n",
        "\n",
        "#1  How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "* To create a 2D NumPy array and calculate the sum of each row, follow these steps:\n",
        "\n",
        "Step 1: Create a 2D NumPy array\n",
        "\n",
        "You can create a 2D array using np.array() or np.random to generate a sample array.\n",
        "\n",
        "Step 2: Calculate the sum of each row\n",
        "\n",
        "Use the np.sum() function with the axis=1 argument to calculate the sum along each row (axis 1 refers to rows, axis 0 refers to columns).\n",
        "\n",
        "Example:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create a 2D NumPy array\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Step 2: Calculate the sum of each row\n",
        "row_sums = np.sum(arr, axis=1)\n",
        "\n",
        "print(\"2D Array:\")\n",
        "print(arr)\n",
        "\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n",
        "\n",
        "Output:\n",
        "\n",
        "2D Array:\n",
        "[[1 2 3]\n",
        " [4 5 6]\n",
        " [7 8 9]]\n",
        "\n",
        "Sum of each row:\n",
        "[ 6 15 24]\n",
        "\n",
        "Explanation:\n",
        " • arr: This is the 2D array created with values.\n",
        " • np.sum(arr, axis=1): This computes the sum along each row.\n",
        " • The first row [1, 2, 3] has a sum of 1+2+3 = 6.\n",
        " • The second row [4, 5, 6] has a sum of 4+5+6 = 15.\n",
        " • The third row [7, 8, 9] has a sum of 7+8+9 = 24.\n",
        "\n",
        "Note:\n",
        " • If you wanted to compute the sum of each column instead, you would use axis=0. For example: np.sum(arr, axis=0).\n",
        "\n",
        "#2 Write a Pandas script to find the mean of a specific column in a DataFrame?\n",
        "* To find the mean of a specific column in a Pandas DataFrame, you can use the mean() function. Here’s a script that demonstrates how to do this:\n",
        "\n",
        "Pandas Script to Find the Mean of a Specific Column\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 35, 40],\n",
        "    'Salary': [50000, 60000, 70000, 80000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the mean of a specific column (e.g., 'Age')\n",
        "mean_age = df['Age'].mean()\n",
        "\n",
        "print(f\"The mean of the 'Age' column is: {mean_age}\")\n",
        "\n",
        "Output:\n",
        "\n",
        "The mean of the 'Age' column is: 32.5\n",
        "\n",
        "Explanation:\n",
        " • df['Age']: This selects the ‘Age’ column in the DataFrame.\n",
        " • .mean(): This calculates the mean (average) of the selected column.\n",
        "\n",
        "You can replace 'Age' with any other column name (e.g., 'Salary') to calculate the mean of that specific column.\n",
        "\n",
        "#3  Create a scatter plot using Matplotlib?\n",
        "* To create a scatter plot using Matplotlib, you can use the scatter() function. Below is an example script that generates a simple scatter plot:\n",
        "\n",
        "Example: Scatter Plot with Matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(x, y, color='blue', marker='o')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Simple Scatter Plot')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "Explanation:\n",
        " • x and y: These are lists that represent the data points to be plotted on the x-axis and y-axis.\n",
        " • plt.scatter(x, y): Creates the scatter plot with x as the x-coordinates and y as the y-coordinates.\n",
        " • color='blue': Specifies the color of the points.\n",
        " • marker='o': Specifies the marker type (a circle in this case).\n",
        " • plt.xlabel(), plt.ylabel(), and plt.title(): Add labels to the x-axis, y-axis, and a title to the plot.\n",
        " • plt.show(): Displays the plot.\n",
        "\n",
        "Output:\n",
        "\n",
        "This will display a simple scatter plot where the points are located based on the x and y values.\n",
        "\n",
        "#4 How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n",
        "\n",
        "* To calculate a correlation matrix and visualize it with a heatmap using Seaborn, follow these steps:\n",
        "\n",
        "Steps:\n",
        " 1. Calculate the correlation matrix: Use the corr() method to calculate the correlation between columns in your DataFrame.\n",
        " 2. Visualize the correlation matrix: Use Seaborn’s heatmap() function to create a heatmap of the correlation matrix.\n",
        "\n",
        "Example:\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6],\n",
        "    'D': [9, 7, 6, 3, 2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Calculate the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Step 2: Visualize the correlation matrix using a heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "\n",
        "# Add a title to the plot\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "Explanation:\n",
        " 1. df.corr(): This method calculates the correlation matrix for all numeric columns in the DataFrame. The correlation values range from -1 (perfect negative correlation) to 1 (perfect positive correlation).\n",
        " 2. sns.heatmap(corr_matrix): This function is used to create the heatmap. The correlation matrix (corr_matrix) is passed as an argument.\n",
        " 3. annot=True: Annotates each cell with the numeric value of the correlation.\n",
        " 4. cmap='coolwarm': Defines the color palette for the heatmap. The coolwarm palette is often used to display positive and negative correlations clearly.\n",
        " 5. fmt='.2f': Specifies the format of the numbers shown in the heatmap (2 decimal places).\n",
        " 6. linewidths=0.5: Adds a small line between each cell for better visual separation.\n",
        " 7. plt.title(): Adds a title to the plot.\n",
        "\n",
        "Output:\n",
        "\n",
        "This code will display a heatmap of the correlation matrix, where each cell is colored according to its correlation value,\n",
        " and the correlation coefficient is annotated inside the cells.\n",
        "\n",
        "#5  Generate a bar plot using Plotly ?\n",
        "\n",
        "* To generate a bar plot using Plotly, you can use the bar() function. Below is an example script that demonstrates how to create a simple bar plot:\n",
        "Here’s an example of how to generate a bar plot using Plotly:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a DataFrame\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'C', 'D'],\n",
        "    'Values': [10, 20, 15, 25]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Create a bar plot\n",
        "fig = px.bar(df, x='Category', y='Values', title='Bar Plot Example',\n",
        "             labels={'Category': 'Category', 'Values': 'Values'},\n",
        "             color='Category')\n",
        "\n",
        "# Step 3: Show the plot\n",
        "fig.show()\n",
        "\n",
        "Key Features\n",
        " 1. px.bar: Used to create the bar plot.\n",
        " 2. Parameters:\n",
        " • x and y: Specify the DataFrame columns for the x-axis and y-axis.\n",
        " • title: Adds a title to the plot.\n",
        " • labels: Sets custom labels for axes.\n",
        " • color: Adds a color distinction for each category.\n",
        "\n",
        "You can customize further with additional arguments. Let me know if you want enhancements like hover effects, annotations, or axis styling!\n",
        "\n",
        "#6 Create a DataFrame and add a new column based on an existing column ?\n",
        "\n",
        "* To create a DataFrame and add a new column based on an existing column,\n",
        " here’s an example in Python using pandas:\n",
        "\n",
        "Example\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Add a new column based on an existing column\n",
        "# For example, adding 5 to the Age column to create a new column 'Age_in_5_years'\n",
        "df['Age_in_5_years'] = df['Age'] + 5\n",
        "\n",
        "print(df)\n",
        "\n",
        "Output\n",
        "\n",
        "      Name  Age  Age_in_5_years\n",
        "0    Alice   25             30\n",
        "1      Bob   30             35\n",
        "2  Charlie   35             40\n",
        "\n",
        "Let me know if you’d like further explanation or variations!\n",
        "\n",
        "#7 Write a program to perform element-wise multiplication of two NumPy arrays?\n",
        "*Here’s a Python program to perform element-wise multiplication of two NumPy arrays:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create two NumPy arrays\n",
        "array1 = np.array([1, 2, 3, 4])\n",
        "array2 = np.array([5, 6, 7, 8])\n",
        "\n",
        "# Step 2: Perform element-wise multiplication\n",
        "result = array1 * array2\n",
        "\n",
        "# Step 3: Print the result\n",
        "print(\"Array 1:\", array1)\n",
        "print(\"Array 2:\", array2)\n",
        "print(\"Element-wise multiplication:\", result)\n",
        "\n",
        "Output\n",
        "\n",
        "Array 1: [1 2 3 4]\n",
        "Array 2: [5 6 7 8]\n",
        "Element-wise multiplication: [ 5 12 21 32]\n",
        "\n",
        "Explanation\n",
        " • The * operator performs element-wise multiplication when used with NumPy arrays.\n",
        " • The two arrays must have the same shape, or be broadcastable to the same shape.\n",
        "\n",
        "Let me know if you’d like to explore other operations or features!\n",
        "\n",
        "#8 Create a line plot with multiple lines using Matplotlib?\n",
        "* Here’s an example of creating a line plot with multiple lines using Matplotlib:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define data for multiple lines\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [1, 4, 9, 16, 25]  # Line 1 data\n",
        "y2 = [1, 8, 27, 64, 125]  # Line 2 data\n",
        "\n",
        "# Step 2: Create the plot\n",
        "plt.plot(x, y1, label='y = x^2', color='blue', linestyle='-', marker='o')  # Line 1\n",
        "plt.plot(x, y2, label='y = x^3', color='red', linestyle='--', marker='s')  # Line 2\n",
        "\n",
        "# Step 3: Add plot elements\n",
        "plt.title('Line Plot with Multiple Lines')\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.legend()  # Add a legend\n",
        "plt.grid(True)  # Add a grid\n",
        "plt.tight_layout()  # Adjust layout for readability\n",
        "\n",
        "# Step 4: Display the plot\n",
        "plt.show()\n",
        "\n",
        "Output\n",
        " • A plot with two lines:\n",
        " • Line 1: y = x^2 in blue with circles as markers.\n",
        " • Line 2: y = x^3 in red with squares as markers.\n",
        " • The plot includes:\n",
        " • A title.\n",
        " • Labeled axes.\n",
        " • A legend to distinguish the lines.\n",
        " • A grid for better visualization.\n",
        "\n",
        "\n",
        "#9 Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold?\n",
        "* Here’s an example of generating a Pandas DataFrame and filtering rows where a column value is greater than a specified threshold:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [24, 30, 18, 27]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Filter rows where 'Age' is greater than 25\n",
        "filtered_df = df[df['Age'] > 25]\n",
        "\n",
        "# Step 3: Display the result\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nFiltered DataFrame (Age > 25):\")\n",
        "print(filtered_df)\n",
        "\n",
        "Output\n",
        "\n",
        "Original DataFrame:\n",
        "      Name  Age\n",
        "0    Alice   24\n",
        "1      Bob   30\n",
        "2  Charlie   18\n",
        "3    David   27\n",
        "\n",
        "Filtered DataFrame (Age > 25):\n",
        "    Name  Age\n",
        "1    Bob   30\n",
        "3  David   27\n",
        "\n",
        "Explanation\n",
        " 1. df['Age'] > 25: Creates a boolean mask to check which rows satisfy the condition.\n",
        " 2. df[condition]: Filters the rows where the condition is True.\n",
        "\n",
        "You can adjust the column and threshold based on your requirements. Let me know if you need more examples!\n",
        "\n",
        "#10 Create a histogram using Seaborn to visualize a distribution?\n",
        "* Here’s an example of how to create a histogram using Seaborn to visualize a distribution:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Generate some sample data\n",
        "data = np.random.normal(loc=50, scale=10, size=1000)  # Normal distribution with mean=50 and std=10\n",
        "\n",
        "# Step 2: Create a histogram using Seaborn\n",
        "sns.histplot(data, bins=30, kde=True, color='blue')\n",
        "\n",
        "# Step 3: Customize the plot\n",
        "plt.title('Distribution of Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Step 4: Display the plot\n",
        "plt.show()\n",
        "\n",
        "Key Features\n",
        " 1. sns.histplot:\n",
        " • Plots the histogram.\n",
        " • The kde=True option overlays a Kernel Density Estimate (KDE) curve.\n",
        " • The bins parameter controls the number of bins in the histogram.\n",
        " 2. Customization:\n",
        " • Added title and axis labels using plt.title, plt.xlabel, and plt.ylabel.\n",
        "\n",
        "Output\n",
        " • A histogram with:\n",
        " • Bars representing the frequency of values within each bin.\n",
        " • A smooth KDE curve overlay for better visualization of the data distribution.\n",
        "\n",
        "#11 Perform matrix multiplication using NumPy?\n",
        "*Here’s how to perform matrix multiplication using NumPy:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define two matrices\n",
        "matrix1 = np.array([[1, 2], [3, 4]])\n",
        "matrix2 = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Step 2: Perform matrix multiplication\n",
        "result = np.dot(matrix1, matrix2)  # Alternatively, use matrix1 @ matrix2\n",
        "\n",
        "# Step 3: Print the result\n",
        "print(\"Matrix 1:\")\n",
        "print(matrix1)\n",
        "print(\"\\nMatrix 2:\")\n",
        "print(matrix2)\n",
        "print(\"\\nMatrix Multiplication Result:\")\n",
        "print(result)\n",
        "\n",
        "Output\n",
        "\n",
        "Matrix 1:\n",
        "[[1 2]\n",
        " [3 4]]\n",
        "\n",
        "Matrix 2:\n",
        "[[5 6]\n",
        " [7 8]]\n",
        "\n",
        "Matrix Multiplication Result:\n",
        "[[19 22]\n",
        " [43 50]]\n",
        "\n",
        "Explanation\n",
        " 1. Matrix Multiplication:\n",
        " • Use np.dot() or the @ operator to perform matrix multiplication.\n",
        " • The number of columns in the first matrix must equal the number of rows in the second matrix.\n",
        " 2. Result Calculation:\n",
        " • For each element in the resulting matrix, compute the dot product of the corresponding row from the first matrix and column from the second matrix.\n",
        "\n",
        "Let me know if you’d like to explore additional matrix operations!Here’s how to perform matrix multiplication using NumPy:\n",
        "\n",
        "Code Example\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define two matrices\n",
        "matrix1 = np.array([[1, 2], [3, 4]])\n",
        "matrix2 = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Step 2: Perform matrix multiplication\n",
        "result = np.dot(matrix1, matrix2)  # Alternatively, use matrix1 @ matrix2\n",
        "\n",
        "# Step 3: Print the result\n",
        "print(\"Matrix 1:\")\n",
        "print(matrix1)\n",
        "print(\"\\nMatrix 2:\")\n",
        "print(matrix2)\n",
        "print(\"\\nMatrix Multiplication Result:\")\n",
        "print(result)\n",
        "\n",
        "Output\n",
        "\n",
        "Matrix 1:\n",
        "[[1 2]\n",
        " [3 4]]\n",
        "\n",
        "Matrix 2:\n",
        "[[5 6]\n",
        " [7 8]]\n",
        "\n",
        "Matrix Multiplication Result:\n",
        "[[19 22]\n",
        " [43 50]]\n",
        "\n",
        "Explanation\n",
        " 1. Matrix Multiplication:\n",
        " • Use np.dot() or the @ operator to perform matrix multiplication.\n",
        " • The number of columns in the first matrix must equal the number of rows in the second matrix.\n",
        " 2. Result Calculation:\n",
        " • For each element in the resulting matrix, compute the dot product of the corresponding row from the first matrix and column from the second matrix.\n",
        "\n",
        "#12 Use Pandas to load a CSV file and display its first 5 rows?\n",
        "* Here’s an example of how to use Pandas to load a CSV file and display its first 5 rows.\n",
        "\n",
        "Code Example:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('example.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "Explanation:\n",
        " 1. pd.read_csv('example.csv'): Loads the CSV file named example.csv into a Pandas DataFrame. Make sure the file path is correct.\n",
        " 2. df.head(): Displays the first 5 rows of the DataFrame. By default, head() returns the top 5 rows, but you can pass a number to it, like head(10), to get more rows.\n",
        "\n",
        "Example Input File (example.csv):\n",
        "\n",
        "Name,Age,City\n",
        "Alice,30,New York\n",
        "Bob,25,San Francisco\n",
        "Charlie,35,Los Angeles\n",
        "David,40,Chicago\n",
        "Eve,22,Houston\n",
        "Frank,29,Seattle\n",
        "\n",
        "Output:\n",
        "\n",
        "      Name  Age           City\n",
        "0    Alice   30      New York\n",
        "1      Bob   25  San Francisco\n",
        "2  Charlie   35   Los Angeles\n",
        "3    David   40       Chicago\n",
        "4      Eve   22       Houston\n",
        "\n",
        "#13 Create a 3D scatter plot using Plotly?\n",
        "*To create a 3D sector plot using Plotly, we can use the plotly.graph_objects module and its go.Cone, go.Surface, or go.Mesh3d classes, depending on the requirements. Here’s an example using a cone sector plot to represent data in 3D space:\n",
        "\n",
        "Code Example:\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Define parameters\n",
        "theta = np.linspace(0, 2 * np.pi, 100)  # Angle range\n",
        "r = np.linspace(0, 1, 50)  # Radius range\n",
        "R, T = np.meshgrid(r, theta)  # Meshgrid for polar coordinates\n",
        "X = R * np.cos(T)  # Convert to Cartesian coordinates\n",
        "Y = R * np.sin(T)\n",
        "Z = np.sqrt(X**2 + Y**2)  # Define Z as a function of X and Y\n",
        "\n",
        "# Create the surface plot\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Surface(\n",
        "    x=X, y=Y, z=Z,\n",
        "    colorscale='Viridis',\n",
        "    showscale=True,\n",
        "    opacity=0.8,\n",
        "))\n",
        "\n",
        "# Add labels\n",
        "fig.update_layout(\n",
        "    title=\"3D Sector Plot Example\",\n",
        "    scene=dict(\n",
        "        xaxis_title='X-axis',\n",
        "        yaxis_title='Y-axis',\n",
        "        zaxis_title='Z-axis',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "\n",
        "Explanation:\n",
        " 1. Meshgrid: The np.meshgrid function creates the grid for the polar coordinates (angle theta and radius r), which are then converted to Cartesian coordinates X and Y.\n",
        " 2. Surface Plot: The go.Surface object is used to represent the 3D surface.\n",
        " 3. Customization: You can adjust the opacity, colorscale, and other attributes to fit your specific requirements.\n",
        "\n",
        "This plot shows a 3D cone-like surface where the height Z depends on the radial distance. Let me know if you’d like help customizing the example further!\n",
        "\n"
      ]
    }
  ]
}